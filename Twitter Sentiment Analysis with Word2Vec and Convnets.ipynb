{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis with Gensim Word2Vec and Keras Convolutional Network\n",
    "Giuseppe Bonaccorso (https://www.bonaccorso.eu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajal\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\rajal\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import keras.backend as K\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed (for reproducibility)\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select whether using Keras with or without GPU support\n",
    "# See: https://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will\n",
    "use_gpu = True\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        inter_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU' : 1, \n",
    "                                        'GPU' : 1 if use_gpu else 0})\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from: http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = './data.csv'\n",
    "model_location = './model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse tweet corpus and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35297 4482\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "with open(dataset_location, 'r', encoding='utf-8') as df:\n",
    "    for i, line in enumerate(df):\n",
    "        if i == 0:\n",
    "            # Skip the header\n",
    "            continue\n",
    "\n",
    "        parts = line.strip().split(',')\n",
    "        \n",
    "        # Sentiment (0 = Negative, 1 = Positive)\n",
    "        labels.append(int(parts[0].strip()))\n",
    "        \n",
    "        # Tweet\n",
    "        tweet = parts[1].strip()\n",
    "        if tweet.startswith('\"'):\n",
    "            tweet = tweet[1:]\n",
    "        if tweet.endswith('\"'):\n",
    "            tweet = tweet[::-1]\n",
    "        \n",
    "        corpus.append(tweet.strip().lower())\n",
    "        \n",
    "print('Corpus size: {}'.format(len(corpus)))\n",
    "print(corpus)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "filepath = 'first.txt' \n",
    "with open(filepath) as fp:  \n",
    "   line = fp.readline()\n",
    "   while line:\n",
    "        corpus.append(line)\n",
    "        labels.append(1)\n",
    "        line = fp.readline()\n",
    "\n",
    "filepath = 'second.txt' \n",
    "with open(filepath) as fp:  \n",
    "   line = fp.readline()\n",
    "   while line:\n",
    "        corpus.append(line)\n",
    "        labels.append(0)\n",
    "        line = fp.readline()\n",
    "        \n",
    "l1= len(corpus)\n",
    "\n",
    "\n",
    "filepath = 'first1.txt' \n",
    "with open(filepath) as fp:  \n",
    "   line = fp.readline()\n",
    "   while line:\n",
    "        corpus.append(line)\n",
    "        labels.append(1)\n",
    "        line = fp.readline()\n",
    "\n",
    "filepath = 'second1.txt' \n",
    "with open(filepath) as fp:  \n",
    "   line = fp.readline()\n",
    "   while line:\n",
    "        corpus.append(line)\n",
    "        labels.append(0)\n",
    "        line = fp.readline()\n",
    "        \n",
    "l2 = len(corpus)\n",
    "diff = l2-l1\n",
    "\n",
    "print(l1,diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tokenize and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkr = RegexpTokenizer('[a-zA-Z0-9@]+')\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = []\n",
    "\n",
    "for i, tweet in enumerate(corpus):\n",
    "    tokens = [stemmer.stem(t) for t in tkr.tokenize(tweet) if not t.startswith('@')]\n",
    "    tokenized_corpus.append(tokens)\n",
    "#print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tokenized corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_location + 'tokenized_corpus.dill', 'wb') as f:\n",
    "    dill.dump(tokenized_corpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tokenized corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_location + 'tokenized_corpus.dill', 'rb') as f:\n",
    "    tokenized_corpus = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 512\n",
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word2Vec\n",
    "word2vec = Word2Vec(sentences=tokenized_corpus,\n",
    "                    size=vector_size, \n",
    "                    window=window_size, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save(model_location + 'word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(model_location + 'word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy word vectors and delete Word2Vec model  and original corpus to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vecs = word2vec.wv\n",
    "\n",
    "del word2vec\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train subset size (0 < size < len(tokenized_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test subset size (0 < size < len(tokenized_corpus) - train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average and max tweet length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tweet length: 16.50685034817366\n",
      "Max tweet length: 45\n"
     ]
    }
   ],
   "source": [
    "avg_length = 0.0\n",
    "max_length = 0\n",
    "\n",
    "for tweet in tokenized_corpus:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "    avg_length += float(len(tweet))\n",
    "    \n",
    "print('Average tweet length: {}'.format(avg_length / float(len(tokenized_corpus))))\n",
    "print('Max tweet length: {}'.format(max_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet max length (number of tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweet_length = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indexes\n",
    "indexes = np.random.choice(len(tokenized_corpus), train_size + test_size, replace=False)\n",
    "\n",
    "X_train = np.zeros((train_size, max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
    "X_test = np.zeros((test_size, max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_test = np.zeros((test_size, 2), dtype=np.int32)\n",
    "\n",
    "     \n",
    "#print(X_train)\n",
    "#print(Y_train)\n",
    "for i, index in enumerate(indexes):\n",
    "    for t, token in enumerate(tokenized_corpus[index]):\n",
    "        if t >= max_tweet_length:\n",
    "            break\n",
    "        \n",
    "        if token not in X_vecs:\n",
    "            continue\n",
    "    \n",
    "        if i < train_size:\n",
    "            X_train[i, t, :] = X_vecs[token]\n",
    "        else:\n",
    "            X_test[i - train_size, t, :] = X_vecs[token]\n",
    "            \n",
    "    if i < train_size:\n",
    "        Y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    else:\n",
    "        Y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 512)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape=(max_tweet_length, vector_size)\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same', input_shape=(max_tweet_length, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35297 samples, validate on 4482 samples\n",
      "Epoch 1/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.2327 - acc: 0.8964 - val_loss: 0.4194 - val_acc: 0.8135\n",
      "Epoch 2/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.2199 - acc: 0.9041 - val_loss: 0.4349 - val_acc: 0.8128\n",
      "Epoch 3/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.2054 - acc: 0.9113 - val_loss: 0.4466 - val_acc: 0.8141\n",
      "Epoch 4/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1903 - acc: 0.9192 - val_loss: 0.4731 - val_acc: 0.8130\n",
      "Epoch 5/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1785 - acc: 0.9246 - val_loss: 0.4670 - val_acc: 0.8146\n",
      "Epoch 6/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1650 - acc: 0.9312 - val_loss: 0.4934 - val_acc: 0.8097\n",
      "Epoch 7/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1577 - acc: 0.9341 - val_loss: 0.5549 - val_acc: 0.8108\n",
      "Epoch 8/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1407 - acc: 0.9425 - val_loss: 0.5820 - val_acc: 0.8141\n",
      "Epoch 9/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1297 - acc: 0.9479 - val_loss: 0.6007 - val_acc: 0.8104\n",
      "Epoch 10/10\n",
      "35297/35297 [==============================] - 37s 1ms/step - loss: 0.1223 - acc: 0.9504 - val_loss: 0.6717 - val_acc: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22aca957ba8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
